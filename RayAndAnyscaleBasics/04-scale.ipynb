{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776e2223",
   "metadata": {},
   "source": [
    "# Scaling topics\n",
    "You put functions and Actors into Anyscale to scale them!\n",
    "Some things are automatic, and some merely easy if you know how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fc4b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "ray.init(address=\"auto\", namespace=\"scaling\", runtime_env={\"pip\":\"requirements.txt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764ae9d",
   "metadata": {},
   "source": [
    "# Monte Carlo\n",
    "This simulation is useful because it gives you an opportunity to see how to scale \n",
    "loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8ada8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def random_batch(batch_size):\n",
    "\n",
    "    total_in = 0\n",
    "    for i in range(batch_size):\n",
    "        x,y = random.uniform(-1,1), random.uniform(-1,1)\n",
    "        if (math.hypot(x,y) <= 1):\n",
    "            total_in += 1\n",
    "    return total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24dd936",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class PiApproximator():\n",
    "    def __init__(self):\n",
    "        self.approximations = []\n",
    "    def approximate(self, num_samples, batch_size):\n",
    "        start = time.time()\n",
    "        num_inside = []\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            num_inside.append(random_batch.remote(batch_size))\n",
    "        pi = (4 * sum(ray.get(num_inside)) / num_samples )\n",
    "        end = time.time()\n",
    "        self.approximations.append({ \"time\":end - start,\n",
    "            \"num_samples\":num_samples,\n",
    "            \"batch_size\":batch_size,\n",
    "            \"pi\":pi})\n",
    "        return pi\n",
    "    def get_approximations(self):\n",
    "        return pd.DataFrame(self.approximations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ray.kill(ray.get_actor(\"approximator\"))\n",
    "approximator = PiApproximator.options(name=\"approximator\").remote()\n",
    "ray.get(approximator.approximate.remote(100, 1))\n",
    "ray.get(approximator.approximate.remote(1000, 1))\n",
    "ray.get(approximator.approximate.remote(1000, 10))\n",
    "ray.get(approximator.approximate.remote(1000, 100))\n",
    "ray.get(approximator.get_approximations.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f39334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these numbers to start talking about efficiency\n",
    "#for x in range(5):\n",
    "    #ray.get([approximator.approximate.remote(i*100000,10000) for i in range(1,20)])\n",
    "df = ray.get(approximator.get_approximations.remote())\n",
    "df.plot(\"num_samples\",\"pi\", kind=\"scatter\")\n",
    "df.plot(\"num_samples\", \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee0d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caebe4fd",
   "metadata": {},
   "source": [
    "# Provisioning\n",
    "This example pre-provisions a cluster.  Autoscaling is a slow-reacting\n",
    "process.  If you need a lot of machines fast, this technique helped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.autoscaler.sdk\n",
    "INIT_CPUS=40\n",
    "tot_cpus = ray.cluster_resources()[\"CPU\"]\n",
    "if tot_cpus < INIT_CPUS:\n",
    "    ray.autoscaler.sdk.request_resources(num_cpus=INIT_CPUS)\n",
    "    # this kind of loop was required when CPU count was in the 1000s\n",
    "    while tot_cpus < INIT_CPUS:\n",
    "        print(f\"Total CPUs so far: {tot_cpus}\")\n",
    "        # wait some amount of time for machines to come up\n",
    "        time.sleep(15)\n",
    "        tot_cpus = ray.cluster_resources()[\"CPU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59785953",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## When you're ready, scale that cluster back down again.\n",
    "ray.autoscaler.sdk.request_resources(num_cpus=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ef4a6",
   "metadata": {},
   "source": [
    "# Ray Serve\n",
    "Ray serve is a library for scaffolding highly parallel endpoints.\n",
    "Since it's integrated with the Ray framework, it's suitable for creating\n",
    "self-contained APIs for model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4dbda",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "from ray import serve\n",
    "import requests\n",
    "from fastapi import FastAPI, Request\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846153ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(name=\"service\", route_prefix=\"/\")\n",
    "@serve.ingress(app)\n",
    "class ImageModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @app.get(\"/image_predict\")\n",
    "    async def predict(self, request : Request):\n",
    "        print(\"I got an API call!  I'm going to slow things down.\")\n",
    "        time.sleep(0.2)\n",
    "        return {\"class_index\": 123}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185197d8",
   "metadata": {},
   "source": [
    "# Start Serve and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.start(detached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a5b2c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#set up actor with 1 replicas\n",
    "ImageModel.options(num_replicas=1)\n",
    "# change the above line to '10' and see RPS go up\n",
    "ImageModel.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1cab1",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://localhost:8000/image_predict\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed493d56",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e28d4",
   "metadata": {},
   "source": [
    "We can of course also use Ray to scale requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd949c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def do_get():\n",
    "    response = requests.get(\"http://localhost:8000/image_predict\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit 10 requests at once\n",
    "start = time.time()\n",
    "ray.get([do_get.remote() for _ in range(10)])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342038c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Now we'll go back and experiment with the replicas\n",
    "ImageModel.options(num_replicas=3)\n",
    "# change the above line to '10' and see RPS go up\n",
    "ImageModel.deploy()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
